{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cff5aa3b-bdb5-4669-9d74-53b627b7e534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "defining experiments\n",
    "'''\n",
    "SEED = 44\n",
    "def experiments():\n",
    "    experiments = [\n",
    "        {\"name\":\"sentence_similarity\",\n",
    "             \"strategy\": \"one_vs_all\",\n",
    "             \"model_type\":\"similarity\", \n",
    "             \"model\":\"sentence-transformers/all-MiniLM-L6-v2\"},\n",
    "        {\"name\":\"zero_shot_simple\", \n",
    "             \"strategy\": \"expand_parents\", \n",
    "             \"model_type\":\"zero-shot\", \n",
    "             \"model\":\"facebook/bart-large-mnli\"},\n",
    "        {\"name\":\"zero_shot_hypothesis\", \n",
    "             \"strategy\": \"expand_parents\", \n",
    "             \"model_type\":\"zero-shot-hypothesis\", \n",
    "             \"model\":\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\"},\n",
    "    ]\n",
    "    return experiments\n",
    "import torch\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b766c44a-ae52-4a83-89aa-74dd7504ca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "loading model\n",
      "sentence-transformers/all-MiniLM-L6-v2 loaded\n",
      "Doing prediction for sentence_similarity\n",
      "... predicting baseterm\n",
      "... predicting facets\n",
      "... predicting F21\n",
      "... predicting F03\n",
      "... predicting F04\n",
      "... predicting F10\n",
      "... predicting F09\n",
      "... predicting F28\n",
      "... predicting F07\n",
      "... predicting F19\n",
      "... predicting F23\n",
      "... predicting F27\n",
      "... predicting F24\n",
      "... predicting F02\n",
      "... predicting F17\n",
      "... predicting F26\n",
      "... predicting F20\n",
      "... predicting F22\n",
      "... predicting F08\n",
      "... predicting F18\n",
      "... predicting F06\n",
      "... predicting F25\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 217\u001b[0m\n\u001b[1;32m    214\u001b[0m   torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    215\u001b[0m   torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mreset_peak_memory_stats()\n\u001b[0;32m--> 217\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[61], line 32\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m hierarchy_name \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhierarchy\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     31\u001b[0m training_df \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 32\u001b[0m test_df \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m(\u001b[38;5;241m500\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#doing predictions\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m... predicting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;250m \u001b[39mhierarchy_name\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "\n",
    "force_cpu = True\n",
    "device = \"cuda\" if torch.cuda.is_available() and not force_cpu else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "def main():\n",
    "    # getting terms hierarchy\n",
    "    terms_df = get_terms_df()\n",
    "    # getting training and test dataset for each hierarchy\n",
    "    datasets = load_datasets()\n",
    "    # Iterating over defined experiments    \n",
    "    for exp in experiments():\n",
    "        # loading model\n",
    "        flush() #ensuring memory is freed before loading a model\n",
    "        exp_name = exp['name']\n",
    "        model_type =  exp[\"model_type\"]\n",
    "        strategy = exp[\"strategy\"]\n",
    "        model = load_model(exp[\"model\"],model_type, device)\n",
    "        print(f\"Doing prediction for {exp['name']}\")\n",
    "        # Iterating on datasets for each hierchy    \n",
    "        for ds in datasets.values():\n",
    "            # extracting data data for the current hierarchy\n",
    "            hierarchy_name = ds[\"hierarchy\"]\n",
    "            training_df = ds[\"training\"]\n",
    "            test_df = ds[\"test\"].head(500)\n",
    "            #doing predictions\n",
    "            print(f\"... predicting { hierarchy_name }\")\n",
    "            predicted_codes = predict_with_strategy(hierarchy_name, training_df, test_df, terms_df, strategy, 10, model, model_type)\n",
    "            #saving results as csv file\n",
    "            res = test_df.copy()\n",
    "            res[\"experiment\"] = exp_name\n",
    "            res[\"hierarchy\"] = hierarchy_name\n",
    "            res[\"predicted_categories\"] = predicted_codes\n",
    "            res[\"in_top_one\"] = res.apply(lambda r: r[\"category\"] in r[\"predicted_categories\"][0:1], axis=1)\n",
    "            res[\"in_top_three\"] = res.apply(lambda r: r[\"category\"] in r[\"predicted_categories\"][0:3], axis=1)\n",
    "            res[\"in_top_ten\"] = res.apply(lambda r: r[\"category\"] in r[\"predicted_categories\"][0:10], axis=1)\n",
    "            res.to_csv(f\"data/result_{hierarchy_name}_{exp_name}.csv\")\n",
    "            \n",
    "    \n",
    "def predict_with_strategy(hierarchy_name, training_df, testing_df, terms_df, strategy, n, model, model_type):\n",
    "    if testing_df is None:\n",
    "       print(\"skipping hierarcy {hierarchy_name}\") \n",
    "    elif strategy == \"one_vs_all\":\n",
    "        hierarchy_codes = testing_df.hierarchy.unique().tolist()\n",
    "        assert(len(hierarchy_codes)==1)\n",
    "        hierarchy_code = hierarchy_codes[0]\n",
    "        text_map = get_hierarchy_map(terms_df, hierarchy_code)  \n",
    "        categories = [* text_map.keys()]\n",
    "        input_texts = testing_df.text.tolist()\n",
    "        predicted_texts = predict(input_texts, categories, hierarchy_name, n, model, model_type)\n",
    "        return [[text_map[text] for text in predicted] for predicted in predicted_texts]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported strategy {strategy}\")\n",
    "\n",
    "def load_model(model, model_type, device):\n",
    "    print(\"loading model\") \n",
    "    if model_type == \"similarity\":\n",
    "        m =  SentenceTransformer(model, device = device)\n",
    "    elif model_type.startswith(\"zero-shot\"):\n",
    "        m = pipeline(\"zero-shot-classification\", model=model, device = device)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type\")\n",
    "    print(f\"{model} loaded\") \n",
    "    return m\n",
    "    \n",
    "def predict(texts, categories, hierarchy_name, n, model, model_type):\n",
    "    results = [*range(0,len(texts))]\n",
    "    if model_type == \"similarity\":\n",
    "        text_vecs =  model.encode(texts, convert_to_tensor = True)\n",
    "        cat_vecs = model.encode(categories, convert_to_tensor = True)\n",
    "        for i in range(0, len(results)):\n",
    "            similarities = [util.pytorch_cos_sim(text_vecs[i], cat_vec).item() for cat_vec in cat_vecs]                \n",
    "            topn = [categories[j] for sim, j in sorted(((sim, j) for j, sim in enumerate(similarities)), reverse=True)][0:n]\n",
    "            results[i] = topn\n",
    "    elif model_type == \"zero-shot\":\n",
    "        for i in range(0, len(results)):\n",
    "            output = classifier(text, categories)\n",
    "            topn = [i for v, i in sorted(((v, i) for i, v in enumerate(output[\"scores\"])), reverse=True)][0:n]\n",
    "            results[i] = [output['labels'][i] for i in topn]\n",
    "    elif model_type == \"zero-shot-hypothesis\":\n",
    "        for i in range(0, len(results)):\n",
    "            hypothesis_template = get_hypothesis_template(hierarchy_name)\n",
    "            output = m_classifier(text, categories, hypothesis_template=hypothesis_template, multi_label=False)\n",
    "            topn = [i for v, i in sorted(((v, i) for i, v in enumerate(output[\"scores\"])), reverse=True)][0:n]\n",
    "            results[i] = [output['labels'][i] for i in topn]\n",
    "    else:\n",
    "        raise ValueError(f\"the model type {model_type} is not supported\")\n",
    "    return results\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "def predict_through_parents(text, hierarchy, n, first = True):\n",
    "    candidates = get_children({\"root\"})\n",
    "    if len(candidates)==0:\n",
    "        return parents\n",
    "    cand_en = [*candidates.keys()]\n",
    "    bests = best_matches(ccam_en, [d for d,c in candidates.items()], top)\n",
    "    best_codes = [(candidates[text], text) for text in bests]\n",
    "\n",
    "    print(ccam_en)\n",
    "    for t in best_codes:\n",
    "        print(f\"---------> {t}\")\n",
    "\n",
    "    rest = search_snomed_hierarchy(ccam_en, best_codes, top, first = False)\n",
    "    ret = [(code, text) for code, text in [*best_codes, *rest]]\n",
    "    if first: # final refinement\n",
    "        retmap = {text:code for code, text in ret}\n",
    "        bests = best_matches(ccam_en, [d for d, c in retmap.items()], top)\n",
    "        best_codes = [(retmap[text], text) for text in bests]\n",
    "        return best_codes\n",
    "    else:\n",
    "        return ret\n",
    "\n",
    "def get_hierarchy_map(terms_df, hierarchy_code):\n",
    "    #terms_df columns: termCode \tparentCode \thierarchyCode \tstatus\n",
    "    children = terms_df[\n",
    "            (terms_df.hierarchyCode == hierarchy_code) & \n",
    "            (terms_df.status == \"APPROVED\" ) \n",
    "        ][[\"termExtendedName\", \"termCode\"]]\n",
    "    return {k:v for k, v in children.values}\n",
    "\n",
    "def get_children_map(parent_codes, hierarchy_code, terms_df):\n",
    "    #terms_df columns: termCode \tparentCode \thierarchyCode \tstatus\n",
    "    assert(terms_df.hierarchyCode.nunique()==1)\n",
    "    children = terms_df[\n",
    "            (terms_df.hierarchyCode == hierarchy_code) & \n",
    "            (terms_df.status == \"APPROVED\" ) & \n",
    "            (terms_df.parentCode.isin(parent_codes))\n",
    "        ][[\"termExtendedName\", \"termCode\"]]\n",
    "    return {k:v for k, v in children.values}\n",
    "\n",
    "def get_hierarchy_question(hierarchy):\n",
    "    if hierarchy == \"baseterm\":\t\n",
    "        return \"This text describes a\"\n",
    "    elif hierarchy == \"F02\":\t#part\tPart-nature\tThis facet describes the nature of the food item or the part of plant or animal it represents.\n",
    "        return \"This is obtained from {}\"\n",
    "    elif hierarchy == \"F01\":    #source: Source\tThis facet describes the plant, animal, other organism or other source from which a raw primary commodity \n",
    "        return \"This is mainly obtained from {}\"\n",
    "    elif hierarchy == \"F27\":   #racsource\tSource-commodities\tThis facet describes the RPC from which an ingredient or derivative has been obtained.\n",
    "        return \"This is derivated from {}\"\n",
    "    elif hierarchy == \"F28\":    #process\tProcess\tThis facet allows recording different characteristics of the food: preservation treatments a food item underwent\n",
    "        return \"This is processed by {}\"\n",
    "    elif hierarchy == \"F04\":    #ingred\tIngredient\tThis facet collects ingredients and/or flavour note.\n",
    "        return \"This contains {}\"\n",
    "    elif hierarchy == \"F06\":\t    #medium\tSurrounding-medium\tThis facet is intended for food packed in any container, together with any additional (    fluid) medium.\n",
    "        return \"This is sell surrounded by {}\"\n",
    "    elif hierarchy == \"F08\":\t    #sweet\tSweetening-agent\tThis facet allows providing information on the added ingredient(s) used to impart sweetness to a food item.\n",
    "        return \"This can be sweeteded with {}\"\n",
    "    elif hierarchy == \"F09\":\t    #fort\tFortification-agent\tThis facet allows providing information on the added ingredient(s) used to fortify a food item.\n",
    "        return \"This can be fortified with {}\"\n",
    "    elif hierarchy == \"F10\":\t#qual\tQualitative-info\tThis facet provides some principal claims related to important nutrients-ingredients, like fat, sugar etc.\n",
    "        return \"When eated provides {}\"\n",
    "    elif hierarchy == \"F17\":\t#cookext\tExtent-of-cooking\tThis facet describes the intensity of heat treatment having been applied to a food item‚Äù.\n",
    "        return \"This is be cooked by {}\"\n",
    "    elif hierarchy == \"F26\":    #\tgen\tGeneric-term\tThis facet allows recording whether the food list code was chosen because of lack of information on the food item.\n",
    "        return \"This description is ambiguous because {}\"\n",
    "    elif hierarchy == \"F21\":    #prod\tProduction-method\tThe facet production method describes the method used to produce the food.\n",
    "        return \"This text is ambiguous because {}\"\n",
    "    elif hierarchy == \"F18\":    #packformat\tPackaging-format\tThis facet is used for packaged food and allows recording the container or wrapping form.\n",
    "        return \"This is sell in a {}\"\n",
    "    elif hierarchy == \"F19\":\t#packmat\tPackaging-material\tThis facet is used for packaged food and allows recording the material constituting the packaging containing.\n",
    "        return \"This is sell in a package made of {}\"\n",
    "    elif hierarchy == \"F03\":     #\tstate\tPhysical-state\tThis facet describes the form (physical aspect) of the food as reported by the consumer .\n",
    "        return \"This seems like a {}\"\n",
    "    elif hierarchy == \"F07\":     #fat\tFat-content\tThis is a facet with numerical descriptors, to allow providing the fat content (as percentage w/w) of a food item.\n",
    "        return \"This contains a fat level of {}\"\n",
    "    elif hierarchy == \"F11\":    #alcohol\tAlcohol-content\tThis is a facet containing information to allow providing the alcohol (ethanol) content (as percentage v/v) of a food item.\n",
    "        return \"This contains an alcohol level of {}\"\n",
    "    elif hierarchy == \"F12\":\t#dough\tDough-Mass\tThis facet is proposed to provide information on the original dough-mass, for bakery products.\n",
    "        return \"This contains a dough of {}\"\n",
    "    elif hierarchy == \"F20\":\t#partcon\tPart-consumed-analysed\tthis facet allows specifying in which form the food item was analysed or consumed.\n",
    "        return \"This is evaluated by analyzing its {}\"\n",
    "    elif hierarchy == \"F22\":    #place\tPreparation-production-place\tThis facet allows recording the place where the food was prepared for consumption.\n",
    "        return \"This prepared in a {}\"\n",
    "    elif hierarchy == \"F23\":    #targcon\tTarget-consumer\tThis facet allows recording different consumer classes intended as target for the food item.\n",
    "        return \"This is eated by {}\"\n",
    "    elif hierarchy == \"F24\":    #use\tIntended-use\tThis facet allows recording the intended use of a food item, in particular with respect to further treatment expected (or not expected) before consumption.\n",
    "        return \"This can gone through {}\"\n",
    "    elif hierarchy == \"F25\":\t#riskingred\tRisky-Ingredient\tThis facet (of specific interest in the microbiological domain) allows recording the presence of microbiologically high-risk ingredients.\n",
    "        return \"This is made with a dangerous {}\"\n",
    "    elif hierarchy == \"F29\":\t#fpurpose\tPurpose-of-raising\tThis facet allows recording the purpose of farming, keeping or breeding (e.g. milk production, egg production).\n",
    "        return \"This is farmed for {}\"\n",
    "    elif hierarchy == \"F30\":\t#replev\tReproductive-level\tThis facet allows recording classes of animals from the point of view of reproduction.\n",
    "        return \"This animal can reproduce by {}\"\n",
    "    elif hierarchy == \"F31\":    #\tanimage\tAnimal-age-class\tThis facet allows recording the classes of the animal used in legislation or in the practice, based on age or development stage.\n",
    "        return \"This animal age is {}\"\n",
    "    elif hierarchy == \"F32\":    #\tgender\tGender\tThis facet allows recording the status of an animal or animal group, with respect to sex.\n",
    "        return \"This animal gender is {}\"\n",
    "    elif hierarchy == \"F33\":\t    #legis\tLegislative-classes\tThis facet allows recording the food additives classes as reported in the legislation in order.\n",
    "        return \"This contains the additive of type {}\"\n",
    "    else:\n",
    "        raise ValueError(f\"The hierarchy {hierarchy} has no question defined\")\n",
    "\n",
    "def get_terms_df():\n",
    "    df = pd.read_pickle(\"data/terms.pickle\")\n",
    "    return df[[\"termCode\", \"termExtendedName\", \"parentCode\", \"hierarchyCode\", \"status\"]]\n",
    "\n",
    "def load_datasets():\n",
    "    f_datasets = \"data/datasets-training-test.pickle\"\n",
    "    with open(f_datasets, \"rb\") as f:\n",
    "        datasets = pickle.load(f)\n",
    "    return datasets\n",
    "\n",
    "def flush():\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34490ab-13c4-40e2-8061-33a9539a7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import torch\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "\n",
    "a = torch.randn(10, 1)\n",
    "b = torch.randn(1, 10) # different row number, for the fun\n",
    "print(a)\n",
    "print(b)\n",
    "# Given that cos_sim(u, v) = dot(u, v) / (norm(u) * norm(v))\n",
    "#                          = dot(u / norm(u), v / norm(v))\n",
    "# We fist normalize the rows, before computing their dot products via transposition:\n",
    "a_norm = a / a.norm(dim=1)[:, None]\n",
    "b_norm = b / b.norm(dim=1)[:, None]\n",
    "res = torch.mm(a_norm, b_norm.transpose(0,1))\n",
    "print(res)\n",
    "#  0.9978 -0.9986 -0.9985\n",
    "# -0.8629  0.9172  0.9172\n",
    "\n",
    "# -------\n",
    "# Let's verify with numpy/scipy if our computations are correct:\n",
    "a_n = a.numpy()\n",
    "b_n = b.numpy()\n",
    "res_n = np.zeros((2, 3))\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # cos_sim(u, v) = 1 - cos_dist(u, v)\n",
    "        res_n[i, j] = 1 - spatial.distance.cosine(a_n[i], b_n[j])\n",
    "print(res_n)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
