{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff5aa3b-bdb5-4669-9d74-53b627b7e534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "defining experiments\n",
    "'''\n",
    "SEED = 44\n",
    "base_name = \"MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\"\n",
    "retrained_path = f'data/{base_name.split(\"/\")[-1]}-zeroshot-retrained'\n",
    "def experiments():\n",
    "    experiments = [\n",
    "        {\"name\":\"zero_shot_hypothesis_retrained\", \n",
    "             \"strategy\": \"expand_parents\", \n",
    "             \"model_type\":\"zero-shot-hypothesis\", \n",
    "             \"model\":retrained_path},\n",
    "        {\"name\":\"sentence_similarity\",\n",
    "             \"strategy\": \"one_vs_all\",\n",
    "             \"model_type\":\"similarity\", \n",
    "             \"model\":\"sentence-transformers/all-MiniLM-L6-v2\"},\n",
    "        {\"name\":\"zero_shot_hypothesis\", \n",
    "             \"strategy\": \"expand_parents\", \n",
    "             \"model_type\":\"zero-shot-hypothesis\", \n",
    "             \"model\":\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\"},\n",
    "             #\"model\":\"MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\"},#\"MoritzLaurer/ModernBERT-large-zeroshot-v2.0\"},#\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\"},\n",
    "             #\"model\":\"MoritzLaurer/deberta-v3-base-zeroshot-v1.1-all-33\"},#\"MoritzLaurer/ModernBERT-large-zeroshot-v2.0\"},#\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\"},\n",
    "        {\"name\":\"zero_shot_simple\", \n",
    "             \"strategy\": \"expand_parents\", \n",
    "             \"model_type\":\"zero-shot\", \n",
    "             \"model\":\"facebook/bart-large-mnli\"},\n",
    "    ]\n",
    "    return experiments\n",
    "import torch\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b766c44a-ae52-4a83-89aa-74dd7504ca69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Doing prediction for zero_shot_hypothesis_retrained\n",
      "loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/deberta-v3-base-zeroshot-v1.1-all-33-zeroshot-retrained loaded\n",
      "... predicting baseterm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|██████████████▉                                                                                                                                                              | 43/500 [01:03<12:11,  1.60s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "force_cpu = False\n",
    "device = \"cuda\" if torch.cuda.is_available() and not force_cpu else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "def main():\n",
    "    # getting terms hierarchy\n",
    "    terms_df = get_terms_df()\n",
    "    # getting training and test dataset for each hierarchy\n",
    "    datasets = load_datasets()\n",
    "    # Iterating over defined experiments    \n",
    "    force = False\n",
    "    for exp in experiments():\n",
    "        # loading model\n",
    "        flush() #ensuring memory is freed before loading a model\n",
    "        exp_name = exp['name']\n",
    "        model_type =  exp[\"model_type\"]\n",
    "        strategy = exp[\"strategy\"]\n",
    "        model = None\n",
    "        # Iterating on datasets for each hierchy    \n",
    "        for ds in datasets.values():\n",
    "            # extracting data data for the current hierarchy\n",
    "            hierarchy_name = ds[\"hierarchy\"]\n",
    "            training_df = ds[\"training\"]\n",
    "            f_results = f\"data/result_{hierarchy_name}_{exp_name}.csv\"\n",
    "            if (not os.path.exists(f_results) or force) and training_df is not None :\n",
    "                #doing predictions\n",
    "                test_df = ds[\"test\"].head(500)\n",
    "                if model is None: \n",
    "                    print(f\"Doing prediction for {exp['name']}\")\n",
    "                    model = load_model(exp[\"model\"],model_type, device)\n",
    "                print(f\"... predicting { hierarchy_name }\")\n",
    "                predicted_codes = predict_with_strategy(hierarchy_name, training_df, test_df, terms_df, strategy, 10, model, model_type)\n",
    "                #saving results as csv file\n",
    "                res = test_df.copy()\n",
    "                res[\"experiment\"] = exp_name\n",
    "                res[\"hierarchy\"] = hierarchy_name\n",
    "                res[\"predicted_categories\"] = predicted_codes\n",
    "                res[\"in_top_one\"] = res.apply(lambda r: r[\"category\"] in r[\"predicted_categories\"][0:1], axis=1)\n",
    "                res[\"in_top_three\"] = res.apply(lambda r: r[\"category\"] in r[\"predicted_categories\"][0:3], axis=1)\n",
    "                res[\"in_top_ten\"] = res.apply(lambda r: r[\"category\"] in r[\"predicted_categories\"][0:10], axis=1)\n",
    "                res.to_csv(f_results)\n",
    "            \n",
    "    \n",
    "def predict_with_strategy(hierarchy_name, training_df, testing_df, terms_df, strategy, n, model, model_type):\n",
    "    if testing_df is None:\n",
    "       print(\"skipping hierarcy {hierarchy_name}\") \n",
    "    elif strategy == \"one_vs_all\":\n",
    "        hierarchy_codes = testing_df.hierarchy.unique().tolist()\n",
    "        assert(len(hierarchy_codes)==1)\n",
    "        hierarchy_code = hierarchy_codes[0]\n",
    "        text_map = get_hierarchy_map(terms_df, hierarchy_code)  \n",
    "        categories = [* text_map.keys()]\n",
    "        input_texts = testing_df.text.tolist()\n",
    "        predicted_texts = predict(input_texts, categories, hierarchy_name, n, model, model_type)\n",
    "        return [[text_map[text] for text in predicted] for predicted in predicted_texts]\n",
    "    elif strategy == \"expand_parents\":\n",
    "        hierarchy_codes = testing_df.hierarchy.unique().tolist()\n",
    "        assert(len(hierarchy_codes)==1)\n",
    "        hierarchy_code = hierarchy_codes[0]\n",
    "        input_texts = testing_df.text.tolist() \n",
    "        predicted_codes = [None for t in input_texts]\n",
    "        i = 0\n",
    "        for input_text in  tqdm(input_texts):\n",
    "            predicted = predict_through_parents(input_text, {\"root\":\"root\"}, hierarchy_name, hierarchy_code, terms_df, 5, model, model_type)\n",
    "            retmap = {text:code for text, code in predicted}\n",
    "            bests = predict([input_text], [*retmap.keys()], hierarchy_name, n, model, model_type)[0] \n",
    "            best_codes = [retmap[text] for text in bests]\n",
    "            predicted_codes[i] = best_codes[0:n]\n",
    "            i = i +1\n",
    "        return predicted_codes\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported strategy {strategy}\")\n",
    "\n",
    "def load_model(model, model_type, device):\n",
    "    print(\"loading model\") \n",
    "    if model_type == \"similarity\":\n",
    "        m =  SentenceTransformer(model, device = device)\n",
    "    elif model_type.startswith(\"zero-shot\"):\n",
    "        if \"retrained\" in model:\n",
    "            mm = AutoModelForSequenceClassification.from_pretrained(model, torch_dtype=torch.float16)\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model, use_fast=False, model_max_length=512)\n",
    "        m = pipeline(\"zero-shot-classification\", model=mm, tokenizer = tokenizer, device = device)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model type\")\n",
    "    print(f\"{model} loaded\") \n",
    "    return m\n",
    "    \n",
    "def predict(texts, categories, hierarchy_name, n, model, model_type):\n",
    "    results = [*range(0,len(texts))]\n",
    "    if model_type == \"similarity\":\n",
    "        text_vecs =  model.encode(texts, convert_to_tensor = True)\n",
    "        cat_vecs = model.encode(categories, convert_to_tensor = True)\n",
    "        for i in range(0, len(results)):\n",
    "            similarities = [util.pytorch_cos_sim(text_vecs[i], cat_vec).item() for cat_vec in cat_vecs]                \n",
    "            topn = [categories[j] for sim, j in sorted(((sim, j) for j, sim in enumerate(similarities)), reverse=True)][0:n]\n",
    "            results[i] = topn\n",
    "    elif model_type == \"zero-shot\":\n",
    "        for i in range(0, len(results)):\n",
    "            output = model(texts[i], categories)\n",
    "            topn = [i for v, i in sorted(((v, i) for i, v in enumerate(output[\"scores\"])), reverse=True)][0:n]\n",
    "            results[i] = [output['labels'][i] for i in topn]\n",
    "    elif model_type == \"zero-shot-hypothesis\":\n",
    "        for i in range(0, len(results)):\n",
    "            hypothesis_template = get_hierarchy_question(hierarchy_name)\n",
    "            output = model(texts[i], categories, hypothesis_template=hypothesis_template, multi_label=False)\n",
    "            topn = [i for v, i in sorted(((v, i) for i, v in enumerate(output[\"scores\"])), reverse=True)][0:n]\n",
    "            results[i] = [output['labels'][i] for i in topn]\n",
    "    else:\n",
    "        raise ValueError(f\"the model type {model_type} is not supported\")\n",
    "    return results\n",
    "\n",
    "    \n",
    "def predict_through_parents(input_text, parents, hierarchy_name, hierarchy_code, terms_df, n, model, model_type):\n",
    "    candidates = get_children_map({*parents.values()}, terms_df, hierarchy_code)\n",
    "    if len(candidates)==0:\n",
    "        return [*parents.items()]\n",
    "    cand_text = [*candidates.keys()]\n",
    "    bests = predict([input_text], [d for d,c in candidates.items()], hierarchy_name, n, model, model_type)[0]\n",
    "    best_codes = {text: candidates[text] for text in bests}\n",
    "\n",
    "    rest = predict_through_parents(input_text, best_codes, hierarchy_name, hierarchy_code, terms_df, n + 2, model, model_type)\n",
    "    ret = [(text, code) for text, code in [*best_codes.items(), *rest]]\n",
    "    return ret\n",
    "    \n",
    "def get_hierarchy_map(terms_df, hierarchy_code):\n",
    "    #terms_df columns: termCode \tparentCode \thierarchyCode \tstatus\n",
    "    children = terms_df[(\n",
    "            (terms_df.hierarchyCode == hierarchy_code) & \n",
    "            (terms_df.status == \"APPROVED\" ) \n",
    "        )][[\"termExtendedName\", \"termCode\"]]\n",
    "    return {k:v for k, v in children.values}\n",
    "\n",
    "def get_children_map(parent_codes, terms_df, hierarchy_code):\n",
    "    #terms_df columns: termCode \tparentCode \thierarchyCode \tstatus\n",
    "    children = terms_df[(\n",
    "            (terms_df.hierarchyCode == hierarchy_code) & \n",
    "            (terms_df.status == \"APPROVED\" ) & \n",
    "            (terms_df.parentCode.isin(parent_codes))\n",
    "        )][[\"termExtendedName\", \"termCode\"]]\n",
    "    return {k:v for k, v in children.values}\n",
    "\n",
    "def get_hierarchy_question(hierarchy):\n",
    "    if hierarchy == \"baseterm\":\t\n",
    "        return \"This food is a: {}\"\n",
    "    elif hierarchy == \"F02\":\t#part\tPart-nature\tThis facet describes the nature of the food item or the part of plant or animal it represents.\n",
    "        return \"This is obtained from {}\"\n",
    "    elif hierarchy == \"F01\":    #source: Source\tThis facet describes the plant, animal, other organism or other source from which a raw primary commodity \n",
    "        return \"This is mainly obtained from {}\"\n",
    "    elif hierarchy == \"F27\":   #racsource\tSource-commodities\tThis facet describes the RPC from which an ingredient or derivative has been obtained.\n",
    "        return \"This is derivated from {}\"\n",
    "    elif hierarchy == \"F28\":    #process\tProcess\tThis facet allows recording different characteristics of the food: preservation treatments a food item underwent\n",
    "        return \"This is processed by {}\"\n",
    "    elif hierarchy == \"F04\":    #ingred\tIngredient\tThis facet collects ingredients and/or flavour note.\n",
    "        return \"This contains {}\"\n",
    "    elif hierarchy == \"F06\":\t    #medium\tSurrounding-medium\tThis facet is intended for food packed in any container, together with any additional (    fluid) medium.\n",
    "        return \"This is sell surrounded by {}\"\n",
    "    elif hierarchy == \"F08\":\t    #sweet\tSweetening-agent\tThis facet allows providing information on the added ingredient(s) used to impart sweetness to a food item.\n",
    "        return \"This can be sweeteded with {}\"\n",
    "    elif hierarchy == \"F09\":\t    #fort\tFortification-agent\tThis facet allows providing information on the added ingredient(s) used to fortify a food item.\n",
    "        return \"This can be fortified with {}\"\n",
    "    elif hierarchy == \"F10\":\t#qual\tQualitative-info\tThis facet provides some principal claims related to important nutrients-ingredients, like fat, sugar etc.\n",
    "        return \"When eated provides {}\"\n",
    "    elif hierarchy == \"F17\":\t#cookext\tExtent-of-cooking\tThis facet describes the intensity of heat treatment having been applied to a food item”.\n",
    "        return \"This is be cooked by {}\"\n",
    "    elif hierarchy == \"F26\":    #\tgen\tGeneric-term\tThis facet allows recording whether the food list code was chosen because of lack of information on the food item.\n",
    "        return \"This description is ambiguous because {}\"\n",
    "    elif hierarchy == \"F21\":    #prod\tProduction-method\tThe facet production method describes the method used to produce the food.\n",
    "        return \"This text is ambiguous because {}\"\n",
    "    elif hierarchy == \"F18\":    #packformat\tPackaging-format\tThis facet is used for packaged food and allows recording the container or wrapping form.\n",
    "        return \"This is sell in a {}\"\n",
    "    elif hierarchy == \"F19\":\t#packmat\tPackaging-material\tThis facet is used for packaged food and allows recording the material constituting the packaging containing.\n",
    "        return \"This is sell in a package made of {}\"\n",
    "    elif hierarchy == \"F03\":     #\tstate\tPhysical-state\tThis facet describes the form (physical aspect) of the food as reported by the consumer .\n",
    "        return \"This seems like a {}\"\n",
    "    elif hierarchy == \"F07\":     #fat\tFat-content\tThis is a facet with numerical descriptors, to allow providing the fat content (as percentage w/w) of a food item.\n",
    "        return \"This contains a fat level of {}\"\n",
    "    elif hierarchy == \"F11\":    #alcohol\tAlcohol-content\tThis is a facet containing information to allow providing the alcohol (ethanol) content (as percentage v/v) of a food item.\n",
    "        return \"This contains an alcohol level of {}\"\n",
    "    elif hierarchy == \"F12\":\t#dough\tDough-Mass\tThis facet is proposed to provide information on the original dough-mass, for bakery products.\n",
    "        return \"This contains a dough of {}\"\n",
    "    elif hierarchy == \"F20\":\t#partcon\tPart-consumed-analysed\tthis facet allows specifying in which form the food item was analysed or consumed.\n",
    "        return \"This is evaluated by analyzing its {}\"\n",
    "    elif hierarchy == \"F22\":    #place\tPreparation-production-place\tThis facet allows recording the place where the food was prepared for consumption.\n",
    "        return \"This prepared in a {}\"\n",
    "    elif hierarchy == \"F23\":    #targcon\tTarget-consumer\tThis facet allows recording different consumer classes intended as target for the food item.\n",
    "        return \"This is eated by {}\"\n",
    "    elif hierarchy == \"F24\":    #use\tIntended-use\tThis facet allows recording the intended use of a food item, in particular with respect to further treatment expected (or not expected) before consumption.\n",
    "        return \"This can gone through {}\"\n",
    "    elif hierarchy == \"F25\":\t#riskingred\tRisky-Ingredient\tThis facet (of specific interest in the microbiological domain) allows recording the presence of microbiologically high-risk ingredients.\n",
    "        return \"This is made with a dangerous {}\"\n",
    "    elif hierarchy == \"F29\":\t#fpurpose\tPurpose-of-raising\tThis facet allows recording the purpose of farming, keeping or breeding (e.g. milk production, egg production).\n",
    "        return \"This is farmed for {}\"\n",
    "    elif hierarchy == \"F30\":\t#replev\tReproductive-level\tThis facet allows recording classes of animals from the point of view of reproduction.\n",
    "        return \"This animal can reproduce by {}\"\n",
    "    elif hierarchy == \"F31\":    #\tanimage\tAnimal-age-class\tThis facet allows recording the classes of the animal used in legislation or in the practice, based on age or development stage.\n",
    "        return \"This animal age is {}\"\n",
    "    elif hierarchy == \"F32\":    #\tgender\tGender\tThis facet allows recording the status of an animal or animal group, with respect to sex.\n",
    "        return \"This animal gender is {}\"\n",
    "    elif hierarchy == \"F33\":\t    #legis\tLegislative-classes\tThis facet allows recording the food additives classes as reported in the legislation in order.\n",
    "        return \"This contains the additive of type {}\"\n",
    "    else:\n",
    "        #print(f\"The hierarchy {hierarchy} has no question defined\")\n",
    "        return \"This text describes a {}\"\n",
    "\n",
    "def get_terms_df():\n",
    "    df = pd.read_pickle(\"data/terms.pickle\")\n",
    "    return df[[\"termCode\", \"termExtendedName\", \"parentCode\", \"hierarchyCode\", \"status\"]]\n",
    "\n",
    "def load_datasets():\n",
    "    f_datasets = \"data/datasets-training-test.pickle\"\n",
    "    with open(f_datasets, \"rb\") as f:\n",
    "        datasets = pickle.load(f)\n",
    "    return datasets\n",
    "\n",
    "def flush():\n",
    "  gc.collect()\n",
    "  torch.cuda.empty_cache()\n",
    "  torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe0aabf-ff8c-4c27-ba98-63a4b47895ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
