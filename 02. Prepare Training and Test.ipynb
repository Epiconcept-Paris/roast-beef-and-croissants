{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2758ee-e892-4e0d-af96-57c06a067aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1861kB [00:00, 2722.34kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Downloading the case study dataset if not already done\n",
    "'''\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm    \n",
    "\n",
    "url = 'https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/opportunities/tender-details/docs/745b51da-4cfd-4ce9-86f6-ae0d6738f67a-CN/FoodEx2-CaseStudy2-Dataset_V1.xlsx'\n",
    "f = 'data/FoodEx2-CaseStudy2-Dataset_V1.xlsx'\n",
    "force = False\n",
    "if not os.path.exists(f) or force:\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(f, \"wb\") as handle:\n",
    "        for data in tqdm(response.iter_content(chunk_size=1024), unit=\"kB\"):\n",
    "            handle.write(data)\n",
    "    print(\"File downloaded succesfully\")\n",
    "else:\n",
    "    print(\"Skipping download, file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "205c2363-09fe-4131-89f9-404d0a829d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find a hierarchy for the code RISKF04, skipping this model\n",
      "Could not find a hierarchy for the code F15, skipping this model\n",
      "Could not find a hierarchy for the code F14, skipping this model\n",
      "Training test datasets stored in data/datasets-training-test.pickle\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Extracting separate training and test datasets for all classification task\n",
    "1. baseterm (expo)\n",
    "2. facets\n",
    "3. F01, F02, etc\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "SEED = 44\n",
    "def main():\n",
    "    f_case = \"data/FoodEx2-CaseStudy2-Dataset_V1.xlsx\"\n",
    "    f_datasets = \"data/datasets-training-test.pickle\"\n",
    "    if not os.path.exists(f_case):\n",
    "        raise FileNotFoundError(\"Please run previous notebook to obtain the case dataset\")\n",
    "    force = False\n",
    "    if not os.path.exists(f_datasets) or force:\n",
    "        case_df = pd.read_excel(f_case)\n",
    "        # adding all term and facet categories\n",
    "        datasets = {\n",
    "            \"baseterm\":term_df(case_df),\n",
    "            \"facets\":facets_df(case_df)\n",
    "        }\n",
    "        # getting all facets categories found\n",
    "        fcats = datasets[\"facets\"].category.unique().tolist()\n",
    "        # iterating trough all facets categories and adding the associated training dataset\n",
    "        for fcat in fcats:\n",
    "            df = facet_df(case_df, fcat)\n",
    "            datasets[fcat] = df\n",
    "    \n",
    "        # splitting into training 90% and testing 10% of data and saving to disk\n",
    "        for hierarchy, df in datasets.items():\n",
    "            if df is not None:\n",
    "                shuffled = df.sample(frac=1, random_state = SEED)\n",
    "                limit = int(len(df)/5)\n",
    "                training = df.iloc[limit:, :]\n",
    "                test = df.iloc[:limit, :]\n",
    "            else:\n",
    "                training = None\n",
    "                test = None\n",
    "                \n",
    "            datasets[hierarchy] = {\"hierarchy\":hierarchy, \"training\":training, \"test\":test}\n",
    "        with open(f_datasets, \"wb\") as f:\n",
    "            pickle.dump(datasets, f)\n",
    "        print(f\"Training test datasets stored in {f_datasets}\")\n",
    "    else:\n",
    "        print(\"Training test datasets file already exist, skipping\")\n",
    "\n",
    "def term_df(df):\n",
    "    df = df.rename(columns={\"ENFOODNAME\":\"text\"})\n",
    "    df[\"hierarchy\"] = \"expo\"\n",
    "    df[\"category\"] = df[\"FACETS\"].str.split(\"#\").str[0]\n",
    "    df = (\n",
    "        df[[\"text\", \"hierarchy\", \"category\"]][pd.notna(df.text) & pd.notna(df.text)]\n",
    "            .drop_duplicates()\n",
    "            .reset_index(drop = True)\n",
    "    \n",
    "    )\n",
    "    return df\n",
    "\n",
    "def facets_df(df):\n",
    "    df = df.rename(columns={\"ENFOODNAME\":\"text\"})\n",
    "    df[\"hierarchy\"] = \"facets\"\n",
    "    # extracting all facets\n",
    "    df[\"category\"] = (\n",
    "        df[\"FACETS\"]\n",
    "            .str.split(\"#\") #split term and facets\n",
    "            .str[1] #choose only facets\n",
    "            .str.split(\"$\") #split on each facet\n",
    "    )\n",
    "    # tranforming multiple facets into different rows\n",
    "    df = df[[\"text\", \"hierarchy\", \"category\"]][pd.notna(df.text) & pd.notna(df.text)].explode(\"category\")\n",
    "\n",
    "    # extracting the facet hierarchy from the facet detail\n",
    "    df[\"category\"] = df[\"category\"].str.split(\".\").str[0]\n",
    "\n",
    "    df = df[pd.notna(df.category)].drop_duplicates().reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "def facet_df(df, fcat):\n",
    "    # gettin a translation from facets to respetive hierrarcy codes\n",
    "    fmap = {fcat:hcode for i, fcat, hcode in pd.read_pickle(\"data/attributes.pickle\")[[\"code\", \"name\"]].itertuples()}    \n",
    "    if fcat not in fmap:\n",
    "        print(f\"Could not find a hierarchy for the code {fcat}, skipping this model\") \n",
    "        return None\n",
    "    df = df.rename(columns={\"ENFOODNAME\":\"text\"})\n",
    "    # extracting all facets\n",
    "    df[\"category\"] = (\n",
    "        df[\"FACETS\"]\n",
    "            .str.split(\"#\") #split term and facets\n",
    "            .str[1] #choose only facets\n",
    "            .str.split(\"$\") #split on each facet\n",
    "    )\n",
    "    df[\"fcat\"] = df.category.str.split(\"\")\n",
    "    # tranforming multiple facets into different rows\n",
    "    df = df[[\"text\", \"category\"]][pd.notna(df.text) & pd.notna(df.text)].explode(\"category\")\n",
    "    # extracting the facet hierarchy from the facet detail\n",
    "    df[\"fcat\"] = df[\"category\"].str.split(\".\").str[0]\n",
    "    # limiting to the expected category\n",
    "    df = df[df.fcat == fcat]\n",
    "    df[\"category\"] = df[\"category\"].str.split(\".\").str[0]\n",
    "    df[\"hierarchy\"] = fmap[fcat]\n",
    "\n",
    "\n",
    "    df = df[pd.notna(df.category)][[\"text\", \"hierarchy\", \"category\"]].drop_duplicates().reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11534e30-9e49-4848-9d0a-ac5ead737339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchy:baseterm  : \ttraining: 26813 rows, \ttest: 6703 rows\n",
      "Hierarchy:facets    : \ttraining: 43076 rows, \ttest: 10769 rows\n",
      "Hierarchy:F21       : \ttraining: 608 rows, \ttest: 152 rows\n",
      "Hierarchy:F03       : \ttraining: 3516 rows, \ttest: 878 rows\n",
      "Hierarchy:F04       : \ttraining: 6943 rows, \ttest: 1735 rows\n",
      "Hierarchy:F10       : \ttraining: 6117 rows, \ttest: 1529 rows\n",
      "Hierarchy:F09       : \ttraining: 363 rows, \ttest: 90 rows\n",
      "Hierarchy:F28       : \ttraining: 8638 rows, \ttest: 2159 rows\n",
      "Hierarchy:F07       : \ttraining: 444 rows, \ttest: 110 rows\n",
      "Hierarchy:F19       : \ttraining: 3658 rows, \ttest: 914 rows\n",
      "Hierarchy:F23       : \ttraining: 115 rows, \ttest: 28 rows\n",
      "Hierarchy:F27       : \ttraining: 1069 rows, \ttest: 267 rows\n",
      "Hierarchy:F24       : \ttraining: 334 rows, \ttest: 83 rows\n",
      "Hierarchy:F02       : \ttraining: 297 rows, \ttest: 74 rows\n",
      "Hierarchy:F17       : \ttraining: 1516 rows, \ttest: 378 rows\n",
      "Hierarchy:F26       : \ttraining: 2646 rows, \ttest: 661 rows\n",
      "Hierarchy:F20       : \ttraining: 1772 rows, \ttest: 443 rows\n",
      "Hierarchy:F22       : \ttraining: 3328 rows, \ttest: 832 rows\n",
      "Hierarchy:F08       : \ttraining: 478 rows, \ttest: 119 rows\n",
      "Hierarchy:F18       : \ttraining: 279 rows, \ttest: 69 rows\n",
      "Hierarchy:F06       : \ttraining: 636 rows, \ttest: 158 rows\n",
      "Hierarchy:F25       : \ttraining: 83 rows, \ttest: 20 rows\n",
      "Hierarchy:RISKF04   : \ttraining: None rows, \ttest: None rows\n",
      "Hierarchy:F31       : \ttraining: 15 rows, \ttest: 3 rows\n",
      "Hierarchy:F33       : \ttraining: 24 rows, \ttest: 5 rows\n",
      "Hierarchy:F01       : \ttraining: 103 rows, \ttest: 25 rows\n",
      "Hierarchy:F11       : \ttraining: 29 rows, \ttest: 7 rows\n",
      "Hierarchy:F15       : \ttraining: None rows, \ttest: None rows\n",
      "Hierarchy:F12       : \ttraining: 14 rows, \ttest: 3 rows\n",
      "Hierarchy:F14       : \ttraining: None rows, \ttest: None rows\n"
     ]
    }
   ],
   "source": [
    "# showing training test datasets metricsabs\n",
    "import pickle\n",
    "def showdatasets():\n",
    "    with open(\"data/datasets-training-test.pickle\", \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    for cases in d.values():\n",
    "        h_n = cases[\"hierarchy\"] + \"\".join(\" \" for x in range(0,10 - len(cases[\"hierarchy\"])))\n",
    "\n",
    "        n_tr = len(cases[\"training\"]) if cases[\"training\"] is not None else None\n",
    "        n_te = len(cases[\"test\"]) if cases[\"test\"] is not None else None\n",
    "        print(f'Hierarchy:{ h_n }: \\ttraining: { n_tr } rows, \\ttest: { n_te } rows')\n",
    "showdatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c68d8c4b-b569-4abd-8f23-2cc0f8458830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hierarchy</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>Pork, shoulder with rind,reheated n.s.,canned,...</td>\n",
       "      <td>expo</td>\n",
       "      <td>A0EYQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6704</th>\n",
       "      <td>Pork, shoulder with rind,reheated n.s.,chilled...</td>\n",
       "      <td>expo</td>\n",
       "      <td>A01RG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6705</th>\n",
       "      <td>Pork, shoulder with rind,roasted/baked in oven...</td>\n",
       "      <td>expo</td>\n",
       "      <td>A01RG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6706</th>\n",
       "      <td>Pork, shoulder with rind,roasted/baked in oven...</td>\n",
       "      <td>expo</td>\n",
       "      <td>A01RG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>Pork, shoulder with rind,stewed n.s.,chilled/r...</td>\n",
       "      <td>expo</td>\n",
       "      <td>A01RG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33511</th>\n",
       "      <td>ZZZ-OUD VEGETABLES FOR NASI/BAMI/ETC.-FACETS_D...</td>\n",
       "      <td>expo</td>\n",
       "      <td>A00ZQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33512</th>\n",
       "      <td>ZZZ-OUD VEGETABLES FOR NASI/BAMI/ETC.-FACETS_D...</td>\n",
       "      <td>expo</td>\n",
       "      <td>A00ZQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33513</th>\n",
       "      <td>Βaby food, cereal cream in a jar</td>\n",
       "      <td>expo</td>\n",
       "      <td>A03RJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33514</th>\n",
       "      <td>Βroccoli</td>\n",
       "      <td>expo</td>\n",
       "      <td>A00FN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33515</th>\n",
       "      <td>Τuna, canned with oil</td>\n",
       "      <td>expo</td>\n",
       "      <td>A0FBT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26813 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text hierarchy category\n",
       "6703   Pork, shoulder with rind,reheated n.s.,canned,...      expo    A0EYQ\n",
       "6704   Pork, shoulder with rind,reheated n.s.,chilled...      expo    A01RG\n",
       "6705   Pork, shoulder with rind,roasted/baked in oven...      expo    A01RG\n",
       "6706   Pork, shoulder with rind,roasted/baked in oven...      expo    A01RG\n",
       "6707   Pork, shoulder with rind,stewed n.s.,chilled/r...      expo    A01RG\n",
       "...                                                  ...       ...      ...\n",
       "33511  ZZZ-OUD VEGETABLES FOR NASI/BAMI/ETC.-FACETS_D...      expo    A00ZQ\n",
       "33512  ZZZ-OUD VEGETABLES FOR NASI/BAMI/ETC.-FACETS_D...      expo    A00ZQ\n",
       "33513                   Βaby food, cereal cream in a jar      expo    A03RJ\n",
       "33514                                           Βroccoli      expo    A00FN\n",
       "33515                              Τuna, canned with oil      expo    A0FBT\n",
       "\n",
       "[26813 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing base term training dataset\n",
    "import pickle\n",
    "def showtraining():\n",
    "    with open(\"data/datasets-training-test.pickle\", \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    return d[\"baseterm\"][\"training\"]\n",
    "showtraining()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
