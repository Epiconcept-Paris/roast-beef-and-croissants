{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b2758ee-e892-4e0d-af96-57c06a067aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1861kB [00:00, 2722.34kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Downloading the case study dataset if not already done\n",
    "'''\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm    \n",
    "\n",
    "url = 'https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/opportunities/tender-details/docs/745b51da-4cfd-4ce9-86f6-ae0d6738f67a-CN/FoodEx2-CaseStudy2-Dataset_V1.xlsx'\n",
    "f = 'data/FoodEx2-CaseStudy2-Dataset_V1.xlsx'\n",
    "force = False\n",
    "if not os.path.exists(f) or force:\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(f, \"wb\") as handle:\n",
    "        for data in tqdm(response.iter_content(chunk_size=1024), unit=\"kB\"):\n",
    "            handle.write(data)\n",
    "    print(\"File downloaded succesfully\")\n",
    "else:\n",
    "    print(\"Skipping download, file already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "205c2363-09fe-4131-89f9-404d0a829d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find a hierarchy for the code RISKF04, skipping this model\n",
      "Could not find a hierarchy for the code F15, skipping this model\n",
      "Could not find a hierarchy for the code F14, skipping this model\n",
      "Training test datasets stored in data/datasets-training-test.pickle\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Extracting separate training and test datasets for all classification task\n",
    "1. baseterm (expo)\n",
    "2. facets\n",
    "3. F01, F02, etc\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "SEED = 44\n",
    "def main():\n",
    "    f_case = \"data/FoodEx2-CaseStudy2-Dataset_V1.xlsx\"\n",
    "    f_datasets = \"data/datasets-training-test.pickle\"\n",
    "    if not os.path.exists(f_case):\n",
    "        raise FileNotFoundError(\"Please run previous notebook to obtain the case dataset\")\n",
    "    force = False\n",
    "    if not os.path.exists(f_datasets) or force:\n",
    "        case_df = pd.read_excel(f_case)\n",
    "        # adding all term and facet categories\n",
    "        datasets = {\n",
    "            \"baseterm\":term_df(case_df),\n",
    "            \"facets\":facets_df(case_df)\n",
    "        }\n",
    "        # getting all facets categories found\n",
    "        fcats = datasets[\"facets\"].category.unique().tolist()\n",
    "        # iterating trough all facets categories and adding the associated training dataset\n",
    "        for fcat in fcats:\n",
    "            df = facet_df(case_df, fcat)\n",
    "            datasets[fcat] = df\n",
    "    \n",
    "        # splitting into training 90% and testing 10% of data and saving to disk\n",
    "        for hierarchy, df in datasets.items():\n",
    "            if df is not None:\n",
    "                shuffled = df.sample(frac=1, random_state = SEED)\n",
    "                limit = int(len(df)/5)\n",
    "                training = df.iloc[limit:, :]\n",
    "                test = df.iloc[:limit, :]\n",
    "            else:\n",
    "                training = None\n",
    "                test = None\n",
    "                \n",
    "            datasets[hierarchy] = {\"hierarchy\":hierarchy, \"training\":training, \"test\":test}\n",
    "        with open(f_datasets, \"wb\") as f:\n",
    "            pickle.dump(datasets, f)\n",
    "        print(f\"Training test datasets stored in {f_datasets}\")\n",
    "    else:\n",
    "        print(\"Training test datasets file already exist, skipping\")\n",
    "\n",
    "def term_df(df):\n",
    "    df = df.rename(columns={\"ENFOODNAME\":\"text\"})\n",
    "    df[\"hierarchy\"] = \"expo\"\n",
    "    df[\"category\"] = df[\"FACETS\"].str.split(\"#\").str[0]\n",
    "    df = (\n",
    "        df[[\"text\", \"hierarchy\", \"category\"]][pd.notna(df.text) & pd.notna(df.text)]\n",
    "            .drop_duplicates()\n",
    "            .reset_index(drop = True)\n",
    "    \n",
    "    )\n",
    "    return df\n",
    "\n",
    "def facets_df(df):\n",
    "    df = df.rename(columns={\"ENFOODNAME\":\"text\"})\n",
    "    df[\"hierarchy\"] = \"facets\"\n",
    "    # extracting all facets\n",
    "    df[\"category\"] = (\n",
    "        df[\"FACETS\"]\n",
    "            .str.split(\"#\") #split term and facets\n",
    "            .str[1] #choose only facets\n",
    "            .str.split(\"$\") #split on each facet\n",
    "    )\n",
    "    # tranforming multiple facets into different rows\n",
    "    df = df[[\"text\", \"hierarchy\", \"category\"]][pd.notna(df.text) & pd.notna(df.text)].explode(\"category\")\n",
    "\n",
    "    # extracting the facet hierarchy from the facet detail\n",
    "    df[\"category\"] = df[\"category\"].str.split(\".\").str[0]\n",
    "\n",
    "    df = df[pd.notna(df.category)].drop_duplicates().reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "def facet_df(df, fcat):\n",
    "    # gettin a translation from facets to respetive hierrarcy codes\n",
    "    fmap = {fcat:hcode for i, fcat, hcode in pd.read_pickle(\"data/attributes.pickle\")[[\"code\", \"name\"]].itertuples()}    \n",
    "    if fcat not in fmap:\n",
    "        print(f\"Could not find a hierarchy for the code {fcat}, skipping this model\") \n",
    "        return None\n",
    "    df = df.rename(columns={\"ENFOODNAME\":\"text\"})\n",
    "    # extracting all facets\n",
    "    df[\"category\"] = (\n",
    "        df[\"FACETS\"]\n",
    "            .str.split(\"#\") #split term and facets\n",
    "            .str[1] #choose only facets\n",
    "            .str.split(\"$\") #split on each facet\n",
    "    )\n",
    "    df[\"fcat\"] = df.category.str.split(\"\")\n",
    "    # tranforming multiple facets into different rows\n",
    "    df = df[[\"text\", \"category\"]][pd.notna(df.text) & pd.notna(df.text)].explode(\"category\")\n",
    "    # extracting the facet hierarchy from the facet detail\n",
    "    df[\"fcat\"] = df[\"category\"].str.split(\".\").str[0]\n",
    "    # limiting to the expected category\n",
    "    df = df[df.fcat == fcat]\n",
    "    df[\"category\"] = df[\"category\"].str.split(\".\").str[1]\n",
    "    df[\"hierarchy\"] = fmap[fcat]\n",
    "\n",
    "\n",
    "    df = df[pd.notna(df.category)][[\"text\", \"hierarchy\", \"category\"]].drop_duplicates().reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11534e30-9e49-4848-9d0a-ac5ead737339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchy:baseterm  : \ttraining: 26813 rows, \ttest: 6703 rows\n",
      "Hierarchy:facets    : \ttraining: 43076 rows, \ttest: 10769 rows\n",
      "Hierarchy:F21       : \ttraining: 799 rows, \ttest: 199 rows\n",
      "Hierarchy:F03       : \ttraining: 3968 rows, \ttest: 992 rows\n",
      "Hierarchy:F04       : \ttraining: 11860 rows, \ttest: 2965 rows\n",
      "Hierarchy:F10       : \ttraining: 8854 rows, \ttest: 2213 rows\n",
      "Hierarchy:F09       : \ttraining: 556 rows, \ttest: 139 rows\n",
      "Hierarchy:F28       : \ttraining: 12394 rows, \ttest: 3098 rows\n",
      "Hierarchy:F07       : \ttraining: 455 rows, \ttest: 113 rows\n",
      "Hierarchy:F19       : \ttraining: 3986 rows, \ttest: 996 rows\n",
      "Hierarchy:F23       : \ttraining: 116 rows, \ttest: 28 rows\n",
      "Hierarchy:F27       : \ttraining: 1327 rows, \ttest: 331 rows\n",
      "Hierarchy:F24       : \ttraining: 376 rows, \ttest: 94 rows\n",
      "Hierarchy:F02       : \ttraining: 366 rows, \ttest: 91 rows\n",
      "Hierarchy:F17       : \ttraining: 2665 rows, \ttest: 666 rows\n",
      "Hierarchy:F26       : \ttraining: 3060 rows, \ttest: 765 rows\n",
      "Hierarchy:F20       : \ttraining: 2134 rows, \ttest: 533 rows\n",
      "Hierarchy:F22       : \ttraining: 3558 rows, \ttest: 889 rows\n",
      "Hierarchy:F08       : \ttraining: 500 rows, \ttest: 125 rows\n",
      "Hierarchy:F18       : \ttraining: 280 rows, \ttest: 70 rows\n",
      "Hierarchy:F06       : \ttraining: 712 rows, \ttest: 177 rows\n",
      "Hierarchy:F25       : \ttraining: 83 rows, \ttest: 20 rows\n",
      "Hierarchy:RISKF04   : \ttraining: None rows, \ttest: None rows\n",
      "Hierarchy:F31       : \ttraining: 15 rows, \ttest: 3 rows\n",
      "Hierarchy:F33       : \ttraining: 24 rows, \ttest: 5 rows\n",
      "Hierarchy:F01       : \ttraining: 129 rows, \ttest: 32 rows\n",
      "Hierarchy:F11       : \ttraining: 29 rows, \ttest: 7 rows\n",
      "Hierarchy:F15       : \ttraining: None rows, \ttest: None rows\n",
      "Hierarchy:F12       : \ttraining: 14 rows, \ttest: 3 rows\n",
      "Hierarchy:F14       : \ttraining: None rows, \ttest: None rows\n"
     ]
    }
   ],
   "source": [
    "# showing training test datasets metricsabs\n",
    "import pickle\n",
    "def showdatasets():\n",
    "    with open(\"data/datasets-training-test.pickle\", \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    for cases in d.values():\n",
    "        h_n = cases[\"hierarchy\"] + \"\".join(\" \" for x in range(0,10 - len(cases[\"hierarchy\"])))\n",
    "\n",
    "        n_tr = len(cases[\"training\"]) if cases[\"training\"] is not None else None\n",
    "        n_te = len(cases[\"test\"]) if cases[\"test\"] is not None else None\n",
    "        print(f'Hierarchy:{ h_n }: \\ttraining: { n_tr } rows, \\ttest: { n_te } rows')\n",
    "showdatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c68d8c4b-b569-4abd-8f23-2cc0f8458830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hierarchy</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>ANONYMOUS C ANONYMOUS D  TABLET</td>\n",
       "      <td>fort</td>\n",
       "      <td>A0EXH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>ANONYMOUS C ANONYMOUS D  TABLET</td>\n",
       "      <td>fort</td>\n",
       "      <td>A0EXM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>ANONYMOUS CD ANONYMOUS BOORI TABLET</td>\n",
       "      <td>fort</td>\n",
       "      <td>A0EXH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>ANONYMOUS CD ANONYMOUS BOORI TABLET</td>\n",
       "      <td>fort</td>\n",
       "      <td>A0EXM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>PIRKKA CALCIUM SUPPLEMENT</td>\n",
       "      <td>fort</td>\n",
       "      <td>A0EXH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>ZINC 25MG CAPSULES/TABLETS</td>\n",
       "      <td>fort</td>\n",
       "      <td>A03SM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>ZINC PREPARATION  ANONYMOUS CODE</td>\n",
       "      <td>fort</td>\n",
       "      <td>A0EXE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>ZINC SUPPLEMENT, 15MG</td>\n",
       "      <td>fort</td>\n",
       "      <td>A03SK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>ANONYMOUS COD LIVER OIL 1000MG ONLY</td>\n",
       "      <td>fort</td>\n",
       "      <td>A03SK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>ANONYMOUS COD LIVER OIL 1000MG ONLY</td>\n",
       "      <td>fort</td>\n",
       "      <td>A03SX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>556 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    text hierarchy category\n",
       "139      ANONYMOUS C ANONYMOUS D  TABLET      fort    A0EXH\n",
       "140      ANONYMOUS C ANONYMOUS D  TABLET      fort    A0EXM\n",
       "141  ANONYMOUS CD ANONYMOUS BOORI TABLET      fort    A0EXH\n",
       "142  ANONYMOUS CD ANONYMOUS BOORI TABLET      fort    A0EXM\n",
       "143            PIRKKA CALCIUM SUPPLEMENT      fort    A0EXH\n",
       "..                                   ...       ...      ...\n",
       "690           ZINC 25MG CAPSULES/TABLETS      fort    A03SM\n",
       "691     ZINC PREPARATION  ANONYMOUS CODE      fort    A0EXE\n",
       "692                ZINC SUPPLEMENT, 15MG      fort    A03SK\n",
       "693  ANONYMOUS COD LIVER OIL 1000MG ONLY      fort    A03SK\n",
       "694  ANONYMOUS COD LIVER OIL 1000MG ONLY      fort    A03SX\n",
       "\n",
       "[556 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing base term training dataset\n",
    "import pickle\n",
    "def showtraining():\n",
    "    with open(\"data/datasets-training-test.pickle\", \"rb\") as f:\n",
    "        d = pickle.load(f)\n",
    "    return d[\"F09\"][\"training\"]\n",
    "showtraining()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
