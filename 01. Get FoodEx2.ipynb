{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c17d83de-eb5e-4288-9454-e8325b7ebd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3715kB [00:00, 5787.73kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded succesfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Downloading the FoodEx database if not already done from their public wiki\n",
    "'''\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm    \n",
    "\n",
    "url = 'https://github.com/openefsa/efsa-catalogues/releases/download/12.0/MTX_FULL_12_0.ecf'\n",
    "f = 'data/MTX_FULL_12_0.ecf'\n",
    "force = False\n",
    "if not os.path.exists(f) or force:\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(f, \"wb\") as handle:\n",
    "        for data in tqdm(response.iter_content(chunk_size=1024), unit=\"kB\"):\n",
    "            handle.write(data)\n",
    "    print(\"File downloaded succesfully\")\n",
    "else:\n",
    "    print(\"Skipping download, file already exists\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1fde4421-55f6-46a0-9ff1-24b49530780e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ecf file\n",
      "writing 36 hierarchies to excel and pickle\n",
      "writing 47 attributes to excel and pickle\n",
      "writing 79901 terms to excel and pickle\n",
      "Dataframes saved successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13675740"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Storing FoodEx database in parent-child tabular form if not already done\n",
    "'''\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from zipfile import ZipFile\n",
    "from bs4.element import Tag, NavigableString\n",
    "\n",
    "def main():\n",
    "    f_ecf = 'data/MTX_FULL_12_0.ecf'\n",
    "    f_xl = 'data/MTX_FULL_12_0.xlsx'\n",
    "    force = False\n",
    "    if not os.path.exists(f_ecf):\n",
    "        raise FileNotFoundError(\"Please execute the previous step to download the ecf file\")\n",
    "    print(\"reading ecf file\")\n",
    "    with ZipFile(f_ecf) as zf:\n",
    "        with zf.open('MTX_FULL_12_0.xml') as f:\n",
    "            soup = BeautifulSoup(f, 'xml')\n",
    "    if force:\n",
    "        os.unlink(f_xl)\n",
    "    if not os.path.exists(f_xl):\n",
    "        with pd.ExcelWriter(f_xl, engine='xlsxwriter') as writer:  \n",
    "            hierarchies = get_hierarchies(soup)\n",
    "            print(f\"writing {len(hierarchies)} hierarchies to excel and pickle\")\n",
    "            hierarchies.to_excel(writer,sheet_name='Hierarchies')\n",
    "            hierarchies.to_pickle(\"data/hierarchies.pickle\")\n",
    "            attrs = get_attributes(soup)\n",
    "            print(f\"writing {len(attrs)} attributes to excel and pickle\")\n",
    "            attrs.to_excel(writer,sheet_name='Attributes') \n",
    "            attrs.to_pickle(\"data/attributes.pickle\")\n",
    "            terms = get_terms(soup)\n",
    "            print(f\"writing {len(terms)} terms to excel and pickle\")\n",
    "            terms.to_excel(writer,sheet_name='Terms')   \n",
    "            terms.to_pickle(\"data/terms.pickle\")\n",
    "            print(\"Dataframes saved successfully\")\n",
    "    else:\n",
    "        print(\"Skipping wrinting to file since it exists already\")\n",
    "\n",
    "def leafmap(node, excluded_parents = {}, force_set = False):\n",
    "    res = {}\n",
    "    for desc in node.descendants:\n",
    "        \n",
    "        if type(desc)==Tag and len(desc.contents) == 1 and type(desc.contents[0]) == NavigableString and (desc.parent.name not in excluded_parents):\n",
    "            key = desc.name\n",
    "            val = desc.contents[0].text\n",
    "            if key not in res:\n",
    "                res[key] = val if not force_set else {val}\n",
    "            else:\n",
    "                if type(res[key]) is str:\n",
    "                    res[key] = {res[key]}\n",
    "                res[key].add(val)\n",
    "    return res\n",
    "\n",
    "def get_hierarchies(soup):\n",
    "    hierarchies = pd.DataFrame([leafmap(h) for h in soup.find_all(\"hierarchy\")])\n",
    "    hierarchies[\"hierarchyOrder\"] = hierarchies[\"hierarchyOrder\"].astype(int)\n",
    "    return hierarchies.sort_values(\"hierarchyOrder\", ignore_index = True)\n",
    "\n",
    "def get_attributes(soup):\n",
    "   attrs = pd.DataFrame([leafmap(h) for h in soup.find_all(\"attribute\")])\n",
    "   attrs[\"attributeOrder\"] = attrs[\"attributeOrder\"].astype(int)\n",
    "   return attrs.sort_values(\"attributeOrder\", ignore_index = True)\n",
    "\n",
    "def get_attributes(soup):\n",
    "   attrs = pd.DataFrame([leafmap(h) for h in soup.find_all(\"attribute\")])\n",
    "   attrs[\"attributeOrder\"] = attrs[\"attributeOrder\"].astype(int)\n",
    "   return attrs.sort_values(\"attributeOrder\", ignore_index = True)\n",
    "\n",
    "def get_terms(soup):\n",
    "   nodes = soup.find_all(\"term\")\n",
    "   dicts = []\n",
    "   for node in nodes:\n",
    "       term = leafmap(node, {\"hierarchyAssignment\", \"implicitAttribute\", \"attributeValues\"}) \n",
    "       #extracting hierarchy assignements\n",
    "       found_ha = False\n",
    "       for ia in node.find_all(\"implicitAttribute\"):\n",
    "         attr = ia.find(\"attributeCode\").text\n",
    "         values = {value.text for value in ia.find_all(\"attributeValue\")}\n",
    "         if attr in term:\n",
    "             raise KeyError(\"The implicit attributs is going to override an existuing value, this is unexpected\")\n",
    "         term[attr] = values\n",
    "       for ha in node.find_all(\"hierarchyAssignment\"):\n",
    "           dicts.append({**term, **leafmap(ha)})\n",
    "           found_ha = True\n",
    "       if not found_ha:\n",
    "           dicts.append(term)\n",
    "   df = pd.DataFrame(dicts)\n",
    "   df[\"order\"] = df[\"order\"].astype(int)\n",
    "   return df.sort_values([\"hierarchyCode\", \"parentCode\", \"order\"], ignore_index = True)\n",
    "\n",
    "main()\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
